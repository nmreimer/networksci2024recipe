{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datacleaning\n",
    "import itertools\n",
    "from nltk.probability import FreqDist\n",
    "from ast import literal_eval\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_centrality(G: nx.Graph):\n",
    "    deg = pd.DataFrame(nx.degree_centrality(G).items(), columns=['Id', 'degree_centrality'])\n",
    "    # eig = pd.DataFrame(nx.eigenvector_centrality_numpy(G, weight=\"Weight\").items(), columns=['Id', 'eigenvector_centrality'])\n",
    "    merged = pd.merge(data[['Id','title']], deg, on = \"Id\")\n",
    "    return merged\n",
    "\n",
    "data = pd.read_csv(\"data_small.csv\", converters={\"ingredient_words\": literal_eval,\"instruction_words\": literal_eval})\n",
    "data = data.rename(columns={\"Unnamed: 0\":\"Id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Preheat oven to 350 degrees F (175 degrees C). Grease and flour a 9x13 inch pan. Sift together the flour, cocoa, baking soda and salt. Set aside.\\nIn a large bowl, cream together the margarine and sugar until light and fluffy. Beat in the eggs one at a time, then stir in the vanilla. Beat in the flour mixture alternately with the milk, mixing just until incorporated. Pour batter into prepared pan.\\nBake in the preheated oven for 40 to 45 minutes, or until a toothpick inserted into the center of the cake comes out clean. Allow to cool.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.set_index(\"Id\").loc[\"WPIBK.zCMtomTe4JVnBcdFDOCfryhly\"]['instructions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_instruction = nx.read_gexf(\"recipe_instruction_small.gexf\")\n",
    "graph_ingredient = nx.read_gexf(\"recipe_ingredient_small.gexf\")\n",
    "\n",
    "graph_recipe_instruction_allwords = nx.read_gexf(\"recipe_instruction_nofilter.gexf\")\n",
    "graph_recipe_ingredient_allwords = nx.read_gexf(\"recipe_ingredient_nofilter.gexf\")\n",
    "\n",
    "graph_recipe_instruction_tfidf = nx.read_gexf(\"recipe_instruction_tfidf.gexf\")\n",
    "graph_recipe_ingredient_tfidf = nx.read_gexf(\"recipe_ingredient_tfidf.gexf\")\n",
    "\n",
    "graph_recipe_instruction_ranked_tfidf = nx.read_gexf(\"recipe_instruction_ranked_tfidf.gexf\")\n",
    "graph_recipe_ingredient_ranked_tfidf = nx.read_gexf(\"recipe_ingredient_ranked_tfidf.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_components(G: nx.graph):\n",
    "    graph_CCs = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "\n",
    "    graph_CCs_subgraphs = [G.subgraph(c).copy() for c in graph_CCs]\n",
    "\n",
    "    lens = [len(g) for g in graph_CCs_subgraphs]\n",
    "    s, count = np.unique(np.sort(lens), return_counts=True)\n",
    "    return np.asarray((s,count))\n",
    "\n",
    "def plot_components(data, axes):\n",
    "    a = sns.scatterplot(x = data[0], y = data[1], ax=axes, s=10)\n",
    "    a.set_xscale('log')\n",
    "    a.set_yscale('log')\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize= (6,3), sharey=True)\n",
    "plot_components(count_components(graph_ingredient), axes=axes[0])\n",
    "plot_components(count_components(graph_recipe_ingredient_tfidf), axes=axes[1])\n",
    "axes[0].set_title(\"Original Graph\")\n",
    "axes[1].set_title(\"TFIDF Graph\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_xlabel(\"Size\")\n",
    "axes[1].set_xlabel(\"Size\")\n",
    "fig.suptitle(\"Size of Connected Components using Original and TFIDF Constructions\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('figs/original_tfidf_components.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (do_centrality(graph_ingredient)).sort_values(by = 'degree_centrality', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (do_centrality(graph_instruction)).sort_values(by = 'degree_centrality', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (do_centrality(graph_recipe_ingredient_tfidf)).sort_values(by = 'degree_centrality', ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = [graph_ingredient, graph_instruction, graph_recipe_ingredient_allwords, graph_recipe_instruction_allwords, graph_recipe_ingredient_tfidf, graph_recipe_instruction_tfidf, graph_recipe_ingredient_ranked_tfidf, graph_recipe_instruction_ranked_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_pairs = itertools.combinations(graphs, r=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "names = [\"Original Ingredient\", \"Original Instruction\", \"All Ingredient Words\", \"All Instruction Words\", \"TFIDF Ingredient\", \"TFIDF Instruction\", \"Ranked TFIDF Ingredient\", \"Ranked TFIDF Instruction\"]\n",
    "graph_distance = pd.DataFrame(np.zeros(shape = (len(graphs), len(graphs))), columns=names)\n",
    "graph_distance.insert(0, 'i', names)\n",
    "graph_distance = graph_distance.set_index('i')\n",
    "for i in range(len(graphs)):\n",
    "    for j in range(len(graphs)):\n",
    "        if i>j:\n",
    "            Mi = nx.adjacency_matrix(graphs[i])\n",
    "            Mj = nx.adjacency_matrix(graphs[j])\n",
    "\n",
    "            Mi = Mi/scipy.sparse.linalg.norm(Mi)\n",
    "            Mj = Mj/scipy.sparse.linalg.norm(Mj)\n",
    "            graph_distance.iloc[i,j] = scipy.sparse.linalg.norm(Mi - Mj)\n",
    "\n",
    "#     for j in range(len(graphs)):\n",
    "#         if i<j:\n",
    "#             graph_distance[i,j] = 1\n",
    "            # graph_distance[i,j] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize= (6,6), sharey=True)\n",
    "a=sns.heatmap(graph_distance, annot=True, cmap=\"Blues\", ax=ax, cbar = False, fmt='.3g', mask=(graph_distance==0))\n",
    "a.set_ylabel(\"\")\n",
    "# fig.suptitle(\"Distance Between Alternate Constructions\")\n",
    "fig.tight_layout()\n",
    "plt.savefig('figs/all_graphdistance.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_centralities(G: nx.Graph):\n",
    "    deg = pd.DataFrame(nx.degree_centrality(G).items(), columns=['Id', 'degree_centrality'])\n",
    "    pagerank = pd.DataFrame(nx.pagerank(G, weight=\"Weight\").items(), columns=['Id', 'pagerank_centrality'])\n",
    "    betweenness = pd.DataFrame(nx.betweenness_centrality(G, weight=\"Weight\").items(), columns=['Id', 'betweenness_centrality'])\n",
    "    merged = pd.merge(data, deg, on = \"Id\")\n",
    "    merged = pd.merge(merged, pagerank, on = \"Id\")\n",
    "    merged = pd.merge(merged, betweenness, on = \"Id\")\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruction_ranked_tfidf_cent = do_centralities(graph_recipe_instruction_ranked_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_idf = pd.read_csv(\"instructions_idf.csv\")\n",
    "ingredients_idf = pd.read_csv(\"ingredients_idf.csv\")\n",
    "\n",
    "instructions_idf = instructions_idf.drop(columns= 'Unnamed: 0')\n",
    "ingredients_idf = ingredients_idf.drop(columns= 'Unnamed: 0')\n",
    "\n",
    "def calculate_idf_sum(instructions, idfs):\n",
    "    instruction_words = instructions.split()\n",
    "    wordset = set(idfs['word'])\n",
    "    idfs = idfs.set_index('word')\n",
    "    sum = 0\n",
    "    for word in instruction_words:\n",
    "        if word in wordset: \n",
    "            sum = sum + idfs.loc[word]\n",
    "    return(sum) \n",
    "\n",
    "calculate_idf_sum(\"preheat oven degrees\", instructions_idf)\n",
    "\n",
    "def all_idf_sum(dat, idfs):\n",
    "    dat['sum_idf'] = dat.apply(lambda l: calculate_idf_sum(l['clean_instructions_masked'], idfs=idfs), axis=1)\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instructions_idf = pd.concat([ingredients_idf,instructions_idf])\n",
    "\n",
    "# instruction_ranked_tfidf_cent['sum_idf'] = instruction_ranked_tfidf_cent['clean_instructions_masked']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1,1, figsize= (6,6))\n",
    "# sns.scatterplot(x=instruction_ranked_tfidf_cent['betweenness_centrality'], y=instruction_ranked_tfidf_cent['sum_idf'], size = .1, alpha = .1)\n",
    "# fig.tight_layout()\n",
    "# instruction_ranked_tfidf_cent.to_csv('instruction_ranked_tfidf_cent.csv')\n",
    "# instruction_ranked_tfidf_cent = all_idf_sum(instruction_ranked_tfidf_cent, instructions_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_ranked_tfidf_cent = pd.read_csv('instruction_ranked_tfidf_cent.csv', converters={\"ingredient_words\": literal_eval,\"instruction_words\": literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instruction_ranked_tfidf_cent.sort_values(by='betweenness_centrality', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "stddv = statistics.stdev(instruction_ranked_tfidf_cent['betweenness_centrality'])\n",
    "mean = statistics.mean(instruction_ranked_tfidf_cent['betweenness_centrality'])\n",
    "# sns.histplot(data=instruction_ranked_tfidf_cent, x='betweenness_centrality')\n",
    "\n",
    "A = instruction_ranked_tfidf_cent[instruction_ranked_tfidf_cent['betweenness_centrality'] < mean]\n",
    "A = FreqDist(list(itertools.chain.from_iterable(A[\"instruction_words\"])))\n",
    "B = instruction_ranked_tfidf_cent[instruction_ranked_tfidf_cent['betweenness_centrality'] > mean + 4*stddv]\n",
    "B = FreqDist(list(itertools.chain.from_iterable(B[\"instruction_words\"])))\n",
    "\n",
    "inst1 = ((pd.DataFrame({a:[b] for a, b in [item for item in A.items()]})).T.reset_index())\n",
    "inst2 = ((pd.DataFrame({a:[b] for a, b in [item for item in B.items()]})).T.reset_index())\n",
    "\n",
    "inst1 = inst1.sort_values(by=0, ascending=False).head(20)\n",
    "inst2 = inst2.sort_values(by=0, ascending=False).head(20)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6, 3))\n",
    "\n",
    "a = sns.barplot(y=inst1[0], x=inst1['index'], ax = axes[0])\n",
    "a.tick_params(axis='x', rotation=90)\n",
    "a.set_xlabel(\"\")\n",
    "a.set_ylabel(\"\")\n",
    "a.set_title(\"Instructions\")\n",
    "\n",
    "b = sns.barplot(y=inst2[0], x=inst2['index'], ax = axes[1])\n",
    "b.tick_params(axis='x', rotation=90)\n",
    "b.set_xlabel(\"\")\n",
    "b.set_ylabel(\"\")\n",
    "b.set_title(\"Instructions\")\n",
    "\n",
    "fig.suptitle(\"Word Frequencies\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "stddv = statistics.stdev(instruction_ranked_tfidf_cent['betweenness_centrality'])\n",
    "mean = statistics.mean(instruction_ranked_tfidf_cent['betweenness_centrality'])\n",
    "# sns.histplot(data=instruction_ranked_tfidf_cent, x='betweenness_centrality')\n",
    "\n",
    "A = instruction_ranked_tfidf_cent[instruction_ranked_tfidf_cent['betweenness_centrality'] < mean]\n",
    "A = FreqDist(list(itertools.chain.from_iterable(A[\"instruction_words\"])))\n",
    "B = instruction_ranked_tfidf_cent[instruction_ranked_tfidf_cent['betweenness_centrality'] > mean + 5*stddv]\n",
    "B = FreqDist(list(itertools.chain.from_iterable(B[\"instruction_words\"])))\n",
    "\n",
    "inst1 = ((pd.DataFrame({a:[b] for a, b in [item for item in A.items()]})).T.reset_index()).rename(columns={'index':\"word\",0:'count'})\n",
    "inst2 = ((pd.DataFrame({a:[b] for a, b in [item for item in B.items()]})).T.reset_index()).rename(columns={'index':\"word\",0:'count'})\n",
    "\n",
    "inst1 = inst1.merge(instructions_idf, on = 'word')\n",
    "inst1['weighted_frequency'] = inst1['count'] * (inst1['weight']**2)\n",
    "inst2 = inst2.merge(instructions_idf, on = 'word')\n",
    "inst2['weighted_frequency'] = inst2['count'] * (inst2['weight']**2)\n",
    "\n",
    "inst1 = inst1.sort_values(by='weighted_frequency', ascending=False).head(20)\n",
    "inst2 = inst2.sort_values(by='weighted_frequency', ascending=False).head(20)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6, 3))\n",
    "\n",
    "a = sns.barplot(y=inst1['weighted_frequency'], x=inst1['word'], ax = axes[0])\n",
    "a.tick_params(axis='x', rotation=90)\n",
    "a.set_xlabel(\"\")\n",
    "a.set_ylabel(\"\")\n",
    "a.set_title(\"Instructions\")\n",
    "\n",
    "b = sns.barplot(y=inst2['weighted_frequency'], x=inst2['word'], ax = axes[1])\n",
    "b.tick_params(axis='x', rotation=90)\n",
    "b.set_xlabel(\"\")\n",
    "b.set_ylabel(\"\")\n",
    "b.set_title(\"Instructions\")\n",
    "\n",
    "fig.suptitle(\"Word Frequencies\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_communities = nx.community.louvain_communities(graph_recipe_instruction_ranked_tfidf, resolution=2,seed=2024)\n",
    "ingr_communities = nx.community.louvain_communities(graph_recipe_ingredient_ranked_tfidf, resolution=2,seed=2024)\n",
    "# for level in inst_communities:\n",
    "#     print(sorted([len(com) for com in level])[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_communities = sorted(inst_communities, key=len)[::-1]\n",
    "ingr_communities = sorted(ingr_communities, key=len)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "([len(community) for community in inst_communities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datacleaning.data_for_nodes(inst_communities[0])\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "n=10\n",
    "k=5\n",
    "def title_dist_for_nodes(nodes, axes):\n",
    "    dats = datacleaning.data_for_nodes(nodes)\n",
    "    dats['title_words'] = dats['title'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "    dats['title_words'] = dats['title_words'].str.lower()\n",
    "    dats['title_words'] = dats['title_words'].str.split()\n",
    "    \n",
    "    dats['title_words'] = dats['title_words'].apply(lambda x: [word for word in x if len(word) > 3])\n",
    "    dats['title_words'] = dats['title_words'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    title_words = list(itertools.chain.from_iterable(dats[\"title_words\"]))\n",
    "    title_freqs = pd.DataFrame(sorted(FreqDist(title_words).most_common(k), key=lambda x: x[1], reverse=True))\n",
    "    sns.barplot(x=title_freqs[0], y=title_freqs[1]/np.linalg.norm(title_freqs[1]), ax= axes)\n",
    "    return title_words\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,n, figsize= (12,3), sharey=True)\n",
    "i = 1\n",
    "plt_i = 0\n",
    "for community in inst_communities:\n",
    "    if len(community) < 100:\n",
    "        i = i + 1\n",
    "        continue\n",
    "    if plt_i >= n:\n",
    "        break\n",
    "\n",
    "    title_dist_for_nodes(community, ax[plt_i])\n",
    "    ax[plt_i].tick_params('x', labelrotation=90)\n",
    "    ax[plt_i].set_xlabel(\"Community \" + str(i) + \"\\n n = \" + str(len(community)))\n",
    "    ax[plt_i].set_ylabel(\"\")\n",
    "\n",
    "    plt_i = plt_i + 1\n",
    "    i = i + 1\n",
    "\n",
    "fig.align_xlabels()\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "k=5\n",
    "def title_dist_for_nodes(nodes, axes):\n",
    "    dats = datacleaning.data_for_nodes(nodes)\n",
    "    dats['title_words'] = dats['title'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "    dats['title_words'] = dats['title_words'].str.lower()\n",
    "    dats['title_words'] = dats['title_words'].str.split()\n",
    "    dats['title_words'] = dats['title_words'].apply(lambda x: [word for word in x if len(word) > 3])\n",
    "    dats['title_words'] = dats['title_words'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    \n",
    "    title_words = list(itertools.chain.from_iterable(dats[\"title_words\"]))\n",
    "    title_freqs = pd.DataFrame(list(FreqDist(title_words).items()), columns = [\"word\",\"frequency\"])\n",
    "\n",
    "    title_freqs['weighted_frequency'] = title_freqs['frequency']\n",
    "    title_freqs = title_freqs.sort_values(by = 'weighted_frequency', ascending= False).head(5)\n",
    "\n",
    "    sns.barplot(x=title_freqs['word'], y=title_freqs['weighted_frequency']/np.linalg.norm(title_freqs['weighted_frequency']), ax= axes, errorbar=('ci', 0))\n",
    "    return title_words\n",
    "\n",
    "def plot_communities(communities):\n",
    "    fig, ax = plt.subplots(2,int(n/2), figsize= (7,6), sharey=True)\n",
    "    i = 1\n",
    "    plt_i = 0\n",
    "    plt_j = 0\n",
    "    for community in communities:\n",
    "        if plt_i + int(n/2)*plt_j >= n:\n",
    "            break\n",
    "        if plt_i == int(n/2):\n",
    "            plt_j = 1\n",
    "            plt_i = 0\n",
    "        title_dist_for_nodes(community, ax[plt_j, plt_i])\n",
    "        ax[plt_j, plt_i].tick_params('x', labelrotation=90)\n",
    "        ax[plt_j, plt_i].set_title(\"Community \" + str(i) + \"\\n n = \" + str(len(community)))\n",
    "        ax[plt_j, plt_i].set_ylabel(\"\")\n",
    "        ax[plt_j, plt_i].set_xlabel(\"\")\n",
    "\n",
    "        plt_i = plt_i + 1\n",
    "        i = i + 1\n",
    "    fig.text(-.02, 0.5, 'Frequency', va='center', rotation='vertical', size='large')\n",
    "    # fig.suptitle(\"Title Word Frequency by Instruction Community\")\n",
    "    fig.align_xlabels()\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "plot_communities(inst_communities)\n",
    "\n",
    "plt.savefig('figs/tfidf_instcommunity_titles.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(community) for community in inst_communities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "k=5\n",
    "def title_dist_for_nodes(nodes, axes):\n",
    "    dats = datacleaning.data_for_nodes(nodes)\n",
    "    dats['title_words'] = dats['title'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "    dats['title_words'] = dats['title_words'].str.lower()\n",
    "    dats['title_words'] = dats['title_words'].str.split()\n",
    "    dats['title_words'] = dats['title_words'].apply(lambda x: [word for word in x if len(word) > 3])\n",
    "    dats['title_words'] = dats['title_words'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    \n",
    "    title_words = list(itertools.chain.from_iterable(dats[\"title_words\"]))\n",
    "    title_freqs = pd.DataFrame(list(FreqDist(title_words).items()), columns = [\"word\",\"frequency\"])\n",
    "\n",
    "    title_freqs['weighted_frequency'] = title_freqs['frequency']\n",
    "    title_freqs = title_freqs.sort_values(by = 'weighted_frequency', ascending= False).head(5)\n",
    "\n",
    "    sns.barplot(x=title_freqs['word'], y=title_freqs['weighted_frequency']/np.linalg.norm(title_freqs['weighted_frequency']), ax= axes, errorbar=('ci', 0))\n",
    "    return title_words\n",
    "\n",
    "def plot_communities(communities):\n",
    "    fig, ax = plt.subplots(2,int(n/2), figsize= (7,6), sharey=True)\n",
    "    i = 1\n",
    "    plt_i = 0\n",
    "    plt_j = 0\n",
    "    for community in communities:\n",
    "        if plt_i + int(n/2)*plt_j >= n:\n",
    "            break\n",
    "        if plt_i == int(n/2):\n",
    "            plt_j = 1\n",
    "            plt_i = 0\n",
    "        title_dist_for_nodes(community, ax[plt_j, plt_i])\n",
    "        ax[plt_j, plt_i].tick_params('x', labelrotation=90)\n",
    "        ax[plt_j, plt_i].set_title(\"Community \" + str(i) + \"\\n n = \" + str(len(community)))\n",
    "        ax[plt_j, plt_i].set_ylabel(\"\")\n",
    "        ax[plt_j, plt_i].set_xlabel(\"\")\n",
    "\n",
    "        plt_i = plt_i + 1\n",
    "        i = i + 1\n",
    "    fig.text(-.02, 0.5, 'Frequency', va='center', rotation='vertical', size='large')\n",
    "    # fig.suptitle(\"Title Word Frequency by Ingredient Community\")\n",
    "    fig.align_xlabels()\n",
    "    fig.tight_layout()\n",
    "\n",
    "# why write functions if you just copy them and change the definition? who can stop me\n",
    "plot_communities(ingr_communities)\n",
    "\n",
    "plt.savefig('figs/tfidf_ingrcommunity_titles.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize= (10,7), sharey=True)\n",
    "\n",
    "\n",
    "com = 13\n",
    "a=(1,2)\n",
    "title_dist_for_nodes(inst_communities[com - 1], ax[a])\n",
    "ax[a].tick_params('x', labelrotation=90)\n",
    "ax[a].set_title(\"Community \" + str(com) + \"\\n n = \" + str(len(inst_communities[com - 1])) + \"\\n c = \" + str(round(inst_communities_df.loc[com]['average'], 4)))\n",
    "\n",
    "com = 46\n",
    "a=(1,0)\n",
    "title_dist_for_nodes(inst_communities[com - 1], ax[a])\n",
    "ax[a].tick_params('x', labelrotation=90)\n",
    "ax[a].set_title(\"Community \" + str(com) + \"\\n n = \" + str(len(inst_communities[com - 1])) + \"\\n c = \" + str(round(inst_communities_df.loc[com]['average'], 4)))\n",
    "\n",
    "com = 14\n",
    "a=(0,2)\n",
    "title_dist_for_nodes(inst_communities[com - 1], ax[a])\n",
    "ax[a].tick_params('x', labelrotation=90)\n",
    "ax[a].set_title(\"Community \" + str(com) + \"\\n n = \" + str(len(inst_communities[com - 1])) + \"\\n c = \" + str(round(inst_communities_df.loc[com]['average'], 4)))\n",
    "\n",
    "com = 45\n",
    "a=(1,1)\n",
    "title_dist_for_nodes(inst_communities[com - 1], ax[a])\n",
    "ax[a].tick_params('x', labelrotation=90)\n",
    "ax[a].set_title(\"Community \" + str(com) + \"\\n n = \" + str(len(inst_communities[com - 1])) + \"\\n c = \" + str(round(inst_communities_df.loc[com]['average'], 4)))\n",
    "\n",
    "com = 47\n",
    "a=(0,1)\n",
    "title_dist_for_nodes(inst_communities[com - 1], ax[a])\n",
    "ax[a].tick_params('x', labelrotation=90)\n",
    "ax[a].set_title(\"Community \" + str(com) + \"\\n n = \" + str(len(inst_communities[com - 1])) + \"\\n c = \" + str(round(inst_communities_df.loc[com]['average'], 4)))\n",
    "\n",
    "com = 48\n",
    "a=(0,0)\n",
    "title_dist_for_nodes(inst_communities[com - 1], ax[a])\n",
    "ax[a].tick_params('x', labelrotation=90)\n",
    "ax[a].set_title(\"Community \" + str(com) + \"\\n n = \" + str(len(inst_communities[com - 1])) + \"\\n c = \" + str(round(inst_communities_df.loc[com]['average'], 4)))\n",
    "\n",
    "for i in [(0,0),(0,1),(0,2),(1,0),(1,1),(1,2)]:\n",
    "    ax[i].set_xlabel(\"\")\n",
    "\n",
    "ax[0,0].set_ylabel(\"Frequency\")\n",
    "ax[1,0].set_ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/tfidf_instcommunity_centrality_titles.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[48,47,14,46,45,13]\n",
    "# datacleaning.data_for_nodes(inst_communities[48 - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = 13\n",
    "a=1\n",
    "fig, ax = plt.subplots(1,6, figsize= (12,3), sharey=True)\n",
    "title_dist_for_nodes(inst_communities[com - 1], ax[a])\n",
    "ax[a].tick_params('x', labelrotation=90)\n",
    "ax[a].set_title(\"Community \" + str(com) + \"\\n n = \" + str(len(inst_communities[com - 1])) + \"\\n c = \" + str(round(inst_communities_df.loc[com - 1]['average'], 4)))\n",
    "\n",
    "com = 46\n",
    "a=4\n",
    "title_dist_for_nodes(inst_communities[com - 1], ax[a])\n",
    "ax[a].tick_params('x', labelrotation=90)\n",
    "ax[a].set_title(\"Community \" + str(com) + \"\\n n = \" + str(len(inst_communities[com - 1])) + \"\\n c = \" + str(round(inst_communities_df.loc[com - 1]['average'], 4)))\n",
    "\n",
    "com = 14\n",
    "a=5\n",
    "title_dist_for_nodes(inst_communities[com - 1], ax[a])\n",
    "ax[a].tick_params('x', labelrotation=90)\n",
    "ax[a].set_title(\"Community \" + str(com) + \"\\n n = \" + str(len(inst_communities[com - 1])) + \"\\n c = \" + str(round(inst_communities_df.loc[com - 1]['average'], 4)))\n",
    "\n",
    "com = 45\n",
    "a=2\n",
    "title_dist_for_nodes(inst_communities[com - 1], ax[a])\n",
    "ax[a].tick_params('x', labelrotation=90)\n",
    "ax[a].set_title(\"Community \" + str(com) + \"\\n n = \" + str(len(inst_communities[com - 1])) + \"\\n c = \" + str(round(inst_communities_df.loc[com - 1]['average'], 4)))\n",
    "\n",
    "com = 47\n",
    "a=3\n",
    "title_dist_for_nodes(inst_communities[com - 1], ax[a])\n",
    "ax[a].tick_params('x', labelrotation=90)\n",
    "ax[a].set_title(\"Community \" + str(com) + \"\\n n = \" + str(len(inst_communities[com - 1])) + \"\\n c = \" + str(round(inst_communities_df.loc[com - 1]['average'], 4)))\n",
    "\n",
    "com = 48\n",
    "a=0\n",
    "title_dist_for_nodes(inst_communities[com - 1], ax[a])\n",
    "ax[a].tick_params('x', labelrotation=90)\n",
    "ax[a].set_title(\"Community \" + str(com) + \"\\n n = \" + str(len(inst_communities[com - 1])) + \"\\n c = \" + str(round(inst_communities_df.loc[com - 1]['average'], 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "k=5\n",
    "def title_dist_for_nodes(nodes, axes, column, weights):\n",
    "    dats = datacleaning.data_for_nodes(nodes)\n",
    "    # dats['title_words'] = dats['title'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "    # dats['title_words'] = dats['title_words'].str.lower()\n",
    "    # dats['title_words'] = dats['title_words'].str.split()\n",
    "    dats['title_words'] = dats[column]\n",
    "    dats['title_words'] = dats['title_words'].apply(lambda x: [word for word in x if len(word) > 3])\n",
    "    dats['title_words'] = dats['title_words'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    \n",
    "    title_words = list(itertools.chain.from_iterable(dats[\"title_words\"]))\n",
    "    title_freqs = pd.DataFrame(list(FreqDist(title_words).items()), columns = [\"word\",\"frequency\"])\n",
    "    \n",
    "    title_freqs = title_freqs.merge(weights, on = 'word')\n",
    "\n",
    "    title_freqs['weighted_frequency'] = title_freqs['frequency'] * title_freqs['weight']\n",
    "    title_freqs = title_freqs.sort_values(by = 'weighted_frequency', ascending = False).head(5)\n",
    "\n",
    "    sns.barplot(x=title_freqs['word'], y=title_freqs['weighted_frequency']/np.linalg.norm(title_freqs['weighted_frequency']), ax= axes, errorbar=('ci', 0))\n",
    "    return title_words\n",
    "\n",
    "def plot_communities(communities, column, weights, title):\n",
    "    fig, ax = plt.subplots(2,int(n/2), figsize= (7,6), sharey=True)\n",
    "    i = 1\n",
    "    plt_i = 0\n",
    "    plt_j = 0\n",
    "    for community in communities:\n",
    "        if plt_i + int(n/2)*plt_j >= n:\n",
    "            break\n",
    "        if plt_i == int(n/2):\n",
    "            plt_j = 1\n",
    "            plt_i = 0\n",
    "        title_dist_for_nodes(community, ax[plt_j, plt_i], column, weights)\n",
    "        ax[plt_j, plt_i].tick_params('x', labelrotation=90)\n",
    "        ax[plt_j, plt_i].set_title(\"Community \" + str(i) + \"\\n n = \" + str(len(community)))\n",
    "        ax[plt_j, plt_i].set_ylabel(\"\")\n",
    "        ax[plt_j, plt_i].set_xlabel(\"\")\n",
    "\n",
    "        plt_i = plt_i + 1\n",
    "        i = i + 1\n",
    "    fig.text(-.02, 0.5, 'Weighted Count', va='center', rotation='vertical', size='large')\n",
    "    # fig.suptitle(title)\n",
    "    fig.align_xlabels()\n",
    "    fig.tight_layout()\n",
    "\n",
    "plot_communities(inst_communities,'instruction_words', instructions_idf,title = \"Instruction Words by Instruction Community\")\n",
    "\n",
    "plt.savefig('figs/tfidf_instcommunity_instructions.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_communities(inst_communities,'ingredient_words', ingredients_idf,title = \"Ingredient Words by Instruction Community\")\n",
    "plt.savefig('figs/tfidf_instcommunity_ingredients.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_communities(communities):\n",
    "    coms = sorted(communities, key=len, reverse=True)\n",
    "    lens = [len(g) for g in coms]\n",
    "    # s, count = np.unique(np.sort(lens), return_counts=True)\n",
    "    return lens\n",
    "\n",
    "def plot_components(data, axes):\n",
    "    a = sns.histplot(x = data, ax=axes, binwidth=25)\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize= (6,3), sharex=True, sharey=True)\n",
    "plot_components(count_communities(inst_communities), axes=axes[0])\n",
    "plot_components(count_communities(ingr_communities), axes=axes[1])\n",
    "axes[0].set_title(\"Instruction Communities\")\n",
    "axes[1].set_title(\"Ingredient Communities\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_xlabel(\"Size\")\n",
    "axes[1].set_xlabel(\"Size\")\n",
    "# fig.suptitle(\"Size of Communities in TFIDF Graphs\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('figs/tfidf_community_sizes.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_communities(ingr_communities,'instruction_words', instructions_idf,title = \"Ingredient Words by Instruction Community\")\n",
    "plt.savefig('figs/tfidf_ingrcommunity_instructions.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_communities(ingr_communities,'ingredient_words', ingredients_idf,title = \"Ingredient Words by Instruction Community\")\n",
    "plt.savefig('figs/tfidf_ingrcommunity_ingredients.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ingr_communities) - len(inst_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_ranked_tfidf_cent.set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "inst_communities_df = {}\n",
    "inst_communities_size = {}\n",
    "com_betweenness = {}\n",
    "for com in inst_communities:\n",
    "    inst_communities_df[i] = com\n",
    "    inst_communities_size[i] = len(com)\n",
    "    com_data = pd.DataFrame([rec for rec in com]).rename(columns={0: \"Id\"}).set_index('Id').join(instruction_ranked_tfidf_cent.set_index('Id'))['betweenness_centrality']\n",
    "    com_betweenness[i] = (sum(com_data)/len(com), max(com_data))\n",
    "    i = i+1\n",
    "\n",
    "inst_communities_df = pd.DataFrame(inst_communities_df.items(),columns=['community_num','nodes']).set_index('community_num')\n",
    "\n",
    "\n",
    "inst_communities_size = pd.DataFrame(inst_communities_size.items(),columns=['community_num','size']).set_index('community_num')\n",
    "\n",
    "inst_communities_df = inst_communities_df.join(inst_communities_size)\n",
    "com_betweenness = pd.DataFrame(com_betweenness.items(), columns=['community_num', 'avg_betweenness']).set_index('community_num').sort_values(by='avg_betweenness', ascending = False)\n",
    "com_betweenness = pd.DataFrame(com_betweenness['avg_betweenness'].tolist(), index=com_betweenness.index).rename(columns = {0:'average',1:'max'})\n",
    "inst_communities_df = inst_communities_df.join(com_betweenness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_communities_df['color'] = inst_communities_df.index.isin([48,47,14,46,45,13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_communities_df.sort_values(by='max', ascending=False)\n",
    "\n",
    "sns.scatterplot(data=inst_communities_df, x='size', y='average', hue = 'color',legend=False)\n",
    "plt.xlabel(\"Community Size\")\n",
    "plt.ylabel(\"Average Betweenness\")\n",
    "plt.savefig('figs/tfidf_instcommunity_betweenness.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = inst_communities_df[inst_communities_df['size']>48]\n",
    "\n",
    "A = A[A['size']<54]\n",
    "\n",
    "A = A.reset_index()\n",
    "\n",
    "A.sort_values('average', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = inst_communities_df[inst_communities_df['size']>100]\n",
    "\n",
    "A = A[A['size']<115]\n",
    "\n",
    "A = A.reset_index()\n",
    "\n",
    "A.sort_values('average', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_communities_df.sort_values(by='average', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,4, figsize= (12,3), sharey=True)\n",
    "\n",
    "def title_dist_for_nodes(nodes, axes):\n",
    "    dats = datacleaning.data_for_nodes(nodes)\n",
    "    dats['title_words'] = dats['title'].replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "    dats['title_words'] = dats['title_words'].str.lower()\n",
    "    dats['title_words'] = dats['title_words'].str.split()\n",
    "    dats['title_words'] = dats['title_words'].apply(lambda x: [word for word in x if len(word) > 3])\n",
    "    dats['title_words'] = dats['title_words'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    \n",
    "    title_words = list(itertools.chain.from_iterable(dats[\"title_words\"]))\n",
    "    title_freqs = pd.DataFrame(list(FreqDist(title_words).items()), columns = [\"word\",\"frequency\"])\n",
    "\n",
    "    title_freqs['weighted_frequency'] = title_freqs['frequency']\n",
    "    \n",
    "    title_freqs = title_freqs.sort_values(by = 'weighted_frequency', ascending= False)\n",
    "    print(title_freqs)\n",
    "    title_freqs = title_freqs.head(10)\n",
    "    sns.barplot(x=title_freqs['word'], y=title_freqs['weighted_frequency']/np.linalg.norm(title_freqs['weighted_frequency']), ax= axes, errorbar=('ci', 0))\n",
    "    axes.tick_params('x', labelrotation=90)\n",
    "    return title_words\n",
    "\n",
    "\n",
    "title_dist_for_nodes(inst_communities_df.loc[1]['nodes'], ax[0])\n",
    "title_dist_for_nodes(inst_communities_df.loc[7]['nodes'], ax[1])\n",
    "title_dist_for_nodes(inst_communities_df.loc[18]['nodes'], ax[2])\n",
    "title_dist_for_nodes(inst_communities_df.loc[33]['nodes'], ax[3])\n",
    "\n",
    "# inst_communities_df.loc[list(com_betweenness.index)[1]]['nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacleaning.data_for_nodes(inst_communities_df.loc[33]['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "thing = {}\n",
    "for com in inst_communities:\n",
    "    thing.update({movie:i for movie in com})\n",
    "    i = i+1\n",
    "\n",
    "nx.set_node_attributes(graph_recipe_instruction_ranked_tfidf, thing, \"class\")\n",
    "\n",
    "\n",
    "i = 1\n",
    "thing = {}\n",
    "for com in ingr_communities:\n",
    "    thing.update({movie:i for movie in com})\n",
    "    i = i+1\n",
    "\n",
    "nx.set_node_attributes(graph_recipe_ingredient_ranked_tfidf, thing, \"class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(graph_recipe_instruction_ranked_tfidf, \"recipe_instruction_ranked_tfidf.gexf\")\n",
    "\n",
    "nx.write_gexf(graph_recipe_ingredient_ranked_tfidf, \"recipe_ingredient_ranked_tfidf.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_mm = graph_recipe_instruction_ranked_tfidf\n",
    "\n",
    "merged_G_mm = nx.Graph()\n",
    "added_nodes = {}\n",
    "for node, data in G_mm.nodes(data = True):\n",
    "    if data[\"class\"] not in added_nodes:\n",
    "        new_node = data[\"class\"]\n",
    "        added_nodes[data[\"class\"]] = new_node\n",
    "        merged_G_mm.add_node(new_node, internal_edges = 0)\n",
    "    else:   \n",
    "        new_node = added_nodes[data[\"class\"]]\n",
    "    neighbors = nx.all_neighbors(G_mm, node)\n",
    "    for neighbor in neighbors:\n",
    "        if (G_mm.nodes[neighbor][\"class\"]) == new_node:\n",
    "            updated_internal_edges = merged_G_mm.nodes[data[\"class\"]].get(\"internal_edges\") + (G_mm.get_edge_data(node, neighbor)).get(\"weight\")\n",
    "            nx.set_node_attributes(merged_G_mm, {data[\"class\"]: updated_internal_edges},\"internal_edges\" )\n",
    "\n",
    "        elif merged_G_mm.get_edge_data(G_mm.nodes[neighbor][\"class\"], new_node) == None:\n",
    "            merged_G_mm.add_edge(G_mm.nodes[neighbor][\"class\"], new_node)\n",
    "            nx.set_edge_attributes(merged_G_mm, {(G_mm.nodes[neighbor][\"class\"],new_node):{\"weight\": (G_mm.get_edge_data(node, neighbor)).get(\"weight\")}})\n",
    "\n",
    "        elif merged_G_mm.get_edge_data(G_mm.nodes[neighbor][\"class\"], new_node) != None:\n",
    "            updated_edge_weight = merged_G_mm.get_edge_data(G_mm.nodes[neighbor][\"class\"], new_node).get(\"weight\") + (G_mm.get_edge_data(node, neighbor)).get(\"weight\")\n",
    "            nx.set_edge_attributes(merged_G_mm, {(G_mm.nodes[neighbor][\"class\"], new_node) : {\"weight\" : updated_edge_weight}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(merged_G_mm, \"com_recipe_instruction_ranked_tfidf.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An absurdly dumb way to calculate adjacency matrix difference for particular nodes\n",
    "def dict_distance(dict1, dict2):\n",
    "  output = 0\n",
    "  for key in set(dict1.keys()) | set(dict2.keys()):\n",
    "    if key in dict1 and key in dict2:\n",
    "      output += abs(dict1[key] - dict2[key])\n",
    "    elif key in dict1:\n",
    "      output += abs(dict1[key])\n",
    "    else:\n",
    "      output += abs(dict2[key])\n",
    "  return output\n",
    "\n",
    "def node_distance(node, graph1, graph2):\n",
    "    n1 = {n:graph1[node][n][\"weight\"] for n in graph1[node]}\n",
    "    n2 = {n:graph2[node][n][\"weight\"] for n in graph2[node]}\n",
    "    return dict_distance(n1, n2)\n",
    "\n",
    "# node_distance(list(graph_recipe_instruction_ranked_tfidf.nodes)[1], graph_recipe_ingredient_ranked_tfidf, graph_recipe_instruction_ranked_tfidf)\n",
    "from random import sample\n",
    "\n",
    "def total_distance(G1, G2):\n",
    "  node_distances = {}\n",
    "  for node in list(G1.nodes):\n",
    "      node_distances[node] = (node_distance(node, G1, G2))\n",
    "  node_distances = pd.DataFrame(node_distances.items(), columns=['Id','distance'])\n",
    "  # print(node_distances)\n",
    "  return sum(node_distances['distance'])/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_distance(graph_instruction, graph_recipe_ingredient_ranked_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_distance(graph_instruction, graph_recipe_instruction_ranked_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_distances.set_index('Id').join(data.set_index('Id')).sort_values(by='distance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = datacleaning.data_for_nodes(set([\"hLowosT.nUfY72goOAjACSHrGaDZtjW\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77963/1971350775.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  (Q['instruction_words'])[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['whisk',\n",
       " 'together',\n",
       " 'bowl',\n",
       " 'gradually',\n",
       " 'whisk',\n",
       " 'alternating',\n",
       " 'make',\n",
       " 'smooth',\n",
       " 'batter',\n",
       " 'whisk',\n",
       " 'batter',\n",
       " 'refrigerate',\n",
       " 'least',\n",
       " 'hour',\n",
       " 'pour',\n",
       " 'small',\n",
       " 'bowl',\n",
       " 'heat',\n",
       " 'small',\n",
       " 'skillet',\n",
       " 'medium',\n",
       " 'heat',\n",
       " 'brush',\n",
       " 'skillet',\n",
       " 'using',\n",
       " 'pastry',\n",
       " 'brush',\n",
       " 'ladle',\n",
       " 'enough',\n",
       " 'batter',\n",
       " 'cover',\n",
       " 'bottom',\n",
       " 'skillet',\n",
       " 'swirl',\n",
       " 'skillet',\n",
       " 'cover',\n",
       " 'bottom',\n",
       " 'completely',\n",
       " 'cook',\n",
       " 'crepe',\n",
       " 'turns',\n",
       " 'golden',\n",
       " 'brown',\n",
       " 'bottom',\n",
       " 'flip',\n",
       " 'cook',\n",
       " 'side',\n",
       " 'small',\n",
       " 'brown',\n",
       " 'spots',\n",
       " 'repeat',\n",
       " 'remaining',\n",
       " 'batter',\n",
       " 'brushing',\n",
       " 'skillet',\n",
       " 'prevent',\n",
       " 'sticking',\n",
       " 'set',\n",
       " 'cooked',\n",
       " 'aside',\n",
       " 'layers',\n",
       " 'waxed',\n",
       " 'paper',\n",
       " 'preheat',\n",
       " 'oven',\n",
       " 'degrees',\n",
       " 'degrees',\n",
       " 'mix',\n",
       " 'bowl',\n",
       " 'thoroughly',\n",
       " 'combined',\n",
       " 'spread',\n",
       " 'bottom',\n",
       " 'xinch',\n",
       " 'baking',\n",
       " 'dish',\n",
       " 'place',\n",
       " 'crepe',\n",
       " 'onto',\n",
       " 'work',\n",
       " 'surface',\n",
       " 'spoon',\n",
       " 'line',\n",
       " 'center',\n",
       " 'crepe',\n",
       " 'roll',\n",
       " 'crepe',\n",
       " 'set',\n",
       " 'pan',\n",
       " 'repeat',\n",
       " 'remaining',\n",
       " 'laying',\n",
       " 'filled',\n",
       " 'pan',\n",
       " 'spread',\n",
       " 'remaining',\n",
       " 'filled',\n",
       " 'sprinkle',\n",
       " 'bake',\n",
       " 'preheated',\n",
       " 'oven',\n",
       " 'bubbling',\n",
       " 'slightly',\n",
       " 'browned',\n",
       " 'minutes']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Q['instruction_words'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2024][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
