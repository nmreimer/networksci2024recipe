{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacleaning\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial import distance\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import scipy\n",
    "# https://realpython.com/nltk-nlp-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>picture_link</th>\n",
       "      <th>clean_ingredients</th>\n",
       "      <th>clean_instructions</th>\n",
       "      <th>clean_instructions_masked</th>\n",
       "      <th>title_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5eA5nRW8VgbOry0hsA.SVnrGkt2AdzO</th>\n",
       "      <td>Southern-Style Chocolate Pound Cake</td>\n",
       "      <td>1 cup butter ADVERTISEMENT 1/2 cup shortening ...</td>\n",
       "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
       "      <td>v.IiJhm4GZSZAGtMDWpTfAe6vspLCiu</td>\n",
       "      <td>butter shortening white sugar eggs vanilla ext...</td>\n",
       "      <td>preheat oven degrees degrees grease flour loaf...</td>\n",
       "      <td>preheat oven degrees degrees grease loaf pans ...</td>\n",
       "      <td>[southernstyle, chocolate, pound, cake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIzfv.NycIqtwo58y7fteog1dKRw12O</th>\n",
       "      <td>Pumpkin Pie I</td>\n",
       "      <td>1 egg ADVERTISEMENT 1 tablespoon all-purpose f...</td>\n",
       "      <td>Preheat oven to 450 degrees F (230 degrees C)....</td>\n",
       "      <td>EbVR3lftwDSDeE1MRSGdi1evygKF/D6</td>\n",
       "      <td>egg allpurpose flour white sugar salt pumpkin ...</td>\n",
       "      <td>preheat oven degrees degrees add sugar gradual...</td>\n",
       "      <td>preheat oven degrees degrees add gradually bea...</td>\n",
       "      <td>[pumpkin, pie, i]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFxp0RPK/1PxAnjYiZUS0KztkgYb3iW</th>\n",
       "      <td>Cinnamon Oatmeal Zucchini Cookies</td>\n",
       "      <td>1 1/2 cups butter, softened ADVERTISEMENT 1 1/...</td>\n",
       "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
       "      <td>jG7CnWbsc8cYsoHbreIorq8Uvyzzk/6</td>\n",
       "      <td>butter softened white sugar eggs vanilla extra...</td>\n",
       "      <td>preheat oven degrees degrees grease baking she...</td>\n",
       "      <td>preheat oven degrees degrees grease sheets bea...</td>\n",
       "      <td>[cinnamon, oatmeal, zucchini, cookies]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3yH5Jc6HLmEnJw5ggLqI11oeBiSpwBy</th>\n",
       "      <td>Plum-Oat Drop Biscuits</td>\n",
       "      <td>2 tablespoons white sugar ADVERTISEMENT 1/2 te...</td>\n",
       "      <td>Preheat oven to 450 degrees F (230 degrees C)....</td>\n",
       "      <td>qE58a7Z1Au0GXvPO188iHZZVqna9hLa</td>\n",
       "      <td>white sugar ground cinnamon allpurpose flour r...</td>\n",
       "      <td>preheat oven degrees degrees grease baking she...</td>\n",
       "      <td>preheat oven degrees degrees grease sheet comb...</td>\n",
       "      <td>[plumoat, drop, biscuits]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8lZak.EVdLP9/dukyN72DYHyjseFwV2</th>\n",
       "      <td>Ghirardelli Milk Chocolate Chip Cookies</td>\n",
       "      <td>2 1/4 cups all-purpose flour ADVERTISEMENT 1 t...</td>\n",
       "      <td>Preheat the oven to 375 degrees F. Stir togeth...</td>\n",
       "      <td>50UyVqBQayirbQ47M.8oJvkETheUGFW</td>\n",
       "      <td>allpurpose flour baking soda salt unsalted but...</td>\n",
       "      <td>preheat oven degrees stir together flour bakin...</td>\n",
       "      <td>preheat oven degrees stir together set aside b...</td>\n",
       "      <td>[ghirardelli, milk, chocolate, chip, cookies]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z5ZKH66nGOR2cgkzDl5vGj4DPX/J95O</th>\n",
       "      <td>Sun-Dried Tomato With Fresh Basil Spread</td>\n",
       "      <td>1/2 cup oil-packed sun-dried tomatoes ADVERTIS...</td>\n",
       "      <td>Place sun-dried tomatoes in the work bowl of a...</td>\n",
       "      <td>IV7I3CRDxEMTrdHzOCE3YHxewYs0JQW</td>\n",
       "      <td>oilpacked sundried tomatoes basil leaves ounce...</td>\n",
       "      <td>place sundried tomatoes work bowl food process...</td>\n",
       "      <td>place work bowl food processor pulse coarsely ...</td>\n",
       "      <td>[sundried, tomato, with, fresh, basil, spread]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g1mQzPtIoBSaOaaHSkMj7cObWt0r5.K</th>\n",
       "      <td>Banana Split Martini</td>\n",
       "      <td>ice as needed ADVERTISEMENT 2 fluid ounces whi...</td>\n",
       "      <td>Fill a cocktail shaker with ice; add white cho...</td>\n",
       "      <td>qE58a7Z1Au0GXvPO188iHZZVqna9hLa</td>\n",
       "      <td>ice needed fluid ounces white chocolate liqueu...</td>\n",
       "      <td>fill cocktail shaker ice add white chocolate l...</td>\n",
       "      <td>fill cocktail shaker add creme de cover shake ...</td>\n",
       "      <td>[banana, split, martini]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsDOddsQtDp7xomWY2mQwcoTyLeUfYa</th>\n",
       "      <td>Citrus Glazed Banana Squash</td>\n",
       "      <td>1 1/2 pounds banana squash, peeled and cubed A...</td>\n",
       "      <td>Melt butter in a large skillet over medium hea...</td>\n",
       "      <td>SkAAXlzdZZcQ6UmAO72KI82FiqpAG9y</td>\n",
       "      <td>banana squash peeled cubed butter water needed...</td>\n",
       "      <td>melt butter large skillet medium heat add squa...</td>\n",
       "      <td>melt large skillet medium heat add cubes cover...</td>\n",
       "      <td>[citrus, glazed, banana, squash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CdxL1ghjiOgZTF8mPLi/JdaUW74ARmq</th>\n",
       "      <td>Classic Spanish Sangria</td>\n",
       "      <td>1 lemon ADVERTISEMENT 1 lime ADVERTISEMENT 1 o...</td>\n",
       "      <td>Have the fruit, rum, wine, and orange juice we...</td>\n",
       "      <td>xCSyOeooKYofbXHuZpV5h7prJrWUDhK</td>\n",
       "      <td>lemon lime orange rum white sugar bottle dry r...</td>\n",
       "      <td>fruit rum wine orange juice well chilled slice...</td>\n",
       "      <td>fruit well chilled slice thin rounds place lar...</td>\n",
       "      <td>[classic, spanish, sangria]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zDZUSIRODtz86LgwPyFH3AoMoPO8p.2</th>\n",
       "      <td>Easy Weeknight Beef Stroganoff</td>\n",
       "      <td>1 pound cooked seasoned frozen beef strips, th...</td>\n",
       "      <td>Brown beef strips in 1 tablespoon oil in nonst...</td>\n",
       "      <td>XkCNVqQ2tDuiXm6iX/ECjwIGMSVHIe6</td>\n",
       "      <td>cooked seasoned frozen beef strips thawed pouc...</td>\n",
       "      <td>brown beef strips oil nonstick skillet cook mi...</td>\n",
       "      <td>brown oil nonstick skillet cook minutes stir s...</td>\n",
       "      <td>[easy, weeknight, beef, stroganoff]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    title  \\\n",
       "5eA5nRW8VgbOry0hsA.SVnrGkt2AdzO       Southern-Style Chocolate Pound Cake   \n",
       "DIzfv.NycIqtwo58y7fteog1dKRw12O                             Pumpkin Pie I   \n",
       "TFxp0RPK/1PxAnjYiZUS0KztkgYb3iW         Cinnamon Oatmeal Zucchini Cookies   \n",
       "3yH5Jc6HLmEnJw5ggLqI11oeBiSpwBy                    Plum-Oat Drop Biscuits   \n",
       "8lZak.EVdLP9/dukyN72DYHyjseFwV2   Ghirardelli Milk Chocolate Chip Cookies   \n",
       "...                                                                   ...   \n",
       "z5ZKH66nGOR2cgkzDl5vGj4DPX/J95O  Sun-Dried Tomato With Fresh Basil Spread   \n",
       "g1mQzPtIoBSaOaaHSkMj7cObWt0r5.K                      Banana Split Martini   \n",
       "dsDOddsQtDp7xomWY2mQwcoTyLeUfYa               Citrus Glazed Banana Squash   \n",
       "CdxL1ghjiOgZTF8mPLi/JdaUW74ARmq                   Classic Spanish Sangria   \n",
       "zDZUSIRODtz86LgwPyFH3AoMoPO8p.2            Easy Weeknight Beef Stroganoff   \n",
       "\n",
       "                                                                       ingredients  \\\n",
       "5eA5nRW8VgbOry0hsA.SVnrGkt2AdzO  1 cup butter ADVERTISEMENT 1/2 cup shortening ...   \n",
       "DIzfv.NycIqtwo58y7fteog1dKRw12O  1 egg ADVERTISEMENT 1 tablespoon all-purpose f...   \n",
       "TFxp0RPK/1PxAnjYiZUS0KztkgYb3iW  1 1/2 cups butter, softened ADVERTISEMENT 1 1/...   \n",
       "3yH5Jc6HLmEnJw5ggLqI11oeBiSpwBy  2 tablespoons white sugar ADVERTISEMENT 1/2 te...   \n",
       "8lZak.EVdLP9/dukyN72DYHyjseFwV2  2 1/4 cups all-purpose flour ADVERTISEMENT 1 t...   \n",
       "...                                                                            ...   \n",
       "z5ZKH66nGOR2cgkzDl5vGj4DPX/J95O  1/2 cup oil-packed sun-dried tomatoes ADVERTIS...   \n",
       "g1mQzPtIoBSaOaaHSkMj7cObWt0r5.K  ice as needed ADVERTISEMENT 2 fluid ounces whi...   \n",
       "dsDOddsQtDp7xomWY2mQwcoTyLeUfYa  1 1/2 pounds banana squash, peeled and cubed A...   \n",
       "CdxL1ghjiOgZTF8mPLi/JdaUW74ARmq  1 lemon ADVERTISEMENT 1 lime ADVERTISEMENT 1 o...   \n",
       "zDZUSIRODtz86LgwPyFH3AoMoPO8p.2  1 pound cooked seasoned frozen beef strips, th...   \n",
       "\n",
       "                                                                      instructions  \\\n",
       "5eA5nRW8VgbOry0hsA.SVnrGkt2AdzO  Preheat oven to 350 degrees F (175 degrees C)....   \n",
       "DIzfv.NycIqtwo58y7fteog1dKRw12O  Preheat oven to 450 degrees F (230 degrees C)....   \n",
       "TFxp0RPK/1PxAnjYiZUS0KztkgYb3iW  Preheat oven to 350 degrees F (175 degrees C)....   \n",
       "3yH5Jc6HLmEnJw5ggLqI11oeBiSpwBy  Preheat oven to 450 degrees F (230 degrees C)....   \n",
       "8lZak.EVdLP9/dukyN72DYHyjseFwV2  Preheat the oven to 375 degrees F. Stir togeth...   \n",
       "...                                                                            ...   \n",
       "z5ZKH66nGOR2cgkzDl5vGj4DPX/J95O  Place sun-dried tomatoes in the work bowl of a...   \n",
       "g1mQzPtIoBSaOaaHSkMj7cObWt0r5.K  Fill a cocktail shaker with ice; add white cho...   \n",
       "dsDOddsQtDp7xomWY2mQwcoTyLeUfYa  Melt butter in a large skillet over medium hea...   \n",
       "CdxL1ghjiOgZTF8mPLi/JdaUW74ARmq  Have the fruit, rum, wine, and orange juice we...   \n",
       "zDZUSIRODtz86LgwPyFH3AoMoPO8p.2  Brown beef strips in 1 tablespoon oil in nonst...   \n",
       "\n",
       "                                                    picture_link  \\\n",
       "5eA5nRW8VgbOry0hsA.SVnrGkt2AdzO  v.IiJhm4GZSZAGtMDWpTfAe6vspLCiu   \n",
       "DIzfv.NycIqtwo58y7fteog1dKRw12O  EbVR3lftwDSDeE1MRSGdi1evygKF/D6   \n",
       "TFxp0RPK/1PxAnjYiZUS0KztkgYb3iW  jG7CnWbsc8cYsoHbreIorq8Uvyzzk/6   \n",
       "3yH5Jc6HLmEnJw5ggLqI11oeBiSpwBy  qE58a7Z1Au0GXvPO188iHZZVqna9hLa   \n",
       "8lZak.EVdLP9/dukyN72DYHyjseFwV2  50UyVqBQayirbQ47M.8oJvkETheUGFW   \n",
       "...                                                          ...   \n",
       "z5ZKH66nGOR2cgkzDl5vGj4DPX/J95O  IV7I3CRDxEMTrdHzOCE3YHxewYs0JQW   \n",
       "g1mQzPtIoBSaOaaHSkMj7cObWt0r5.K  qE58a7Z1Au0GXvPO188iHZZVqna9hLa   \n",
       "dsDOddsQtDp7xomWY2mQwcoTyLeUfYa  SkAAXlzdZZcQ6UmAO72KI82FiqpAG9y   \n",
       "CdxL1ghjiOgZTF8mPLi/JdaUW74ARmq  xCSyOeooKYofbXHuZpV5h7prJrWUDhK   \n",
       "zDZUSIRODtz86LgwPyFH3AoMoPO8p.2  XkCNVqQ2tDuiXm6iX/ECjwIGMSVHIe6   \n",
       "\n",
       "                                                                 clean_ingredients  \\\n",
       "5eA5nRW8VgbOry0hsA.SVnrGkt2AdzO  butter shortening white sugar eggs vanilla ext...   \n",
       "DIzfv.NycIqtwo58y7fteog1dKRw12O  egg allpurpose flour white sugar salt pumpkin ...   \n",
       "TFxp0RPK/1PxAnjYiZUS0KztkgYb3iW  butter softened white sugar eggs vanilla extra...   \n",
       "3yH5Jc6HLmEnJw5ggLqI11oeBiSpwBy  white sugar ground cinnamon allpurpose flour r...   \n",
       "8lZak.EVdLP9/dukyN72DYHyjseFwV2  allpurpose flour baking soda salt unsalted but...   \n",
       "...                                                                            ...   \n",
       "z5ZKH66nGOR2cgkzDl5vGj4DPX/J95O  oilpacked sundried tomatoes basil leaves ounce...   \n",
       "g1mQzPtIoBSaOaaHSkMj7cObWt0r5.K  ice needed fluid ounces white chocolate liqueu...   \n",
       "dsDOddsQtDp7xomWY2mQwcoTyLeUfYa  banana squash peeled cubed butter water needed...   \n",
       "CdxL1ghjiOgZTF8mPLi/JdaUW74ARmq  lemon lime orange rum white sugar bottle dry r...   \n",
       "zDZUSIRODtz86LgwPyFH3AoMoPO8p.2  cooked seasoned frozen beef strips thawed pouc...   \n",
       "\n",
       "                                                                clean_instructions  \\\n",
       "5eA5nRW8VgbOry0hsA.SVnrGkt2AdzO  preheat oven degrees degrees grease flour loaf...   \n",
       "DIzfv.NycIqtwo58y7fteog1dKRw12O  preheat oven degrees degrees add sugar gradual...   \n",
       "TFxp0RPK/1PxAnjYiZUS0KztkgYb3iW  preheat oven degrees degrees grease baking she...   \n",
       "3yH5Jc6HLmEnJw5ggLqI11oeBiSpwBy  preheat oven degrees degrees grease baking she...   \n",
       "8lZak.EVdLP9/dukyN72DYHyjseFwV2  preheat oven degrees stir together flour bakin...   \n",
       "...                                                                            ...   \n",
       "z5ZKH66nGOR2cgkzDl5vGj4DPX/J95O  place sundried tomatoes work bowl food process...   \n",
       "g1mQzPtIoBSaOaaHSkMj7cObWt0r5.K  fill cocktail shaker ice add white chocolate l...   \n",
       "dsDOddsQtDp7xomWY2mQwcoTyLeUfYa  melt butter large skillet medium heat add squa...   \n",
       "CdxL1ghjiOgZTF8mPLi/JdaUW74ARmq  fruit rum wine orange juice well chilled slice...   \n",
       "zDZUSIRODtz86LgwPyFH3AoMoPO8p.2  brown beef strips oil nonstick skillet cook mi...   \n",
       "\n",
       "                                                         clean_instructions_masked  \\\n",
       "5eA5nRW8VgbOry0hsA.SVnrGkt2AdzO  preheat oven degrees degrees grease loaf pans ...   \n",
       "DIzfv.NycIqtwo58y7fteog1dKRw12O  preheat oven degrees degrees add gradually bea...   \n",
       "TFxp0RPK/1PxAnjYiZUS0KztkgYb3iW  preheat oven degrees degrees grease sheets bea...   \n",
       "3yH5Jc6HLmEnJw5ggLqI11oeBiSpwBy  preheat oven degrees degrees grease sheet comb...   \n",
       "8lZak.EVdLP9/dukyN72DYHyjseFwV2  preheat oven degrees stir together set aside b...   \n",
       "...                                                                            ...   \n",
       "z5ZKH66nGOR2cgkzDl5vGj4DPX/J95O  place work bowl food processor pulse coarsely ...   \n",
       "g1mQzPtIoBSaOaaHSkMj7cObWt0r5.K  fill cocktail shaker add creme de cover shake ...   \n",
       "dsDOddsQtDp7xomWY2mQwcoTyLeUfYa  melt large skillet medium heat add cubes cover...   \n",
       "CdxL1ghjiOgZTF8mPLi/JdaUW74ARmq  fruit well chilled slice thin rounds place lar...   \n",
       "zDZUSIRODtz86LgwPyFH3AoMoPO8p.2  brown oil nonstick skillet cook minutes stir s...   \n",
       "\n",
       "                                                                    title_words  \n",
       "5eA5nRW8VgbOry0hsA.SVnrGkt2AdzO         [southernstyle, chocolate, pound, cake]  \n",
       "DIzfv.NycIqtwo58y7fteog1dKRw12O                               [pumpkin, pie, i]  \n",
       "TFxp0RPK/1PxAnjYiZUS0KztkgYb3iW          [cinnamon, oatmeal, zucchini, cookies]  \n",
       "3yH5Jc6HLmEnJw5ggLqI11oeBiSpwBy                       [plumoat, drop, biscuits]  \n",
       "8lZak.EVdLP9/dukyN72DYHyjseFwV2   [ghirardelli, milk, chocolate, chip, cookies]  \n",
       "...                                                                         ...  \n",
       "z5ZKH66nGOR2cgkzDl5vGj4DPX/J95O  [sundried, tomato, with, fresh, basil, spread]  \n",
       "g1mQzPtIoBSaOaaHSkMj7cObWt0r5.K                        [banana, split, martini]  \n",
       "dsDOddsQtDp7xomWY2mQwcoTyLeUfYa                [citrus, glazed, banana, squash]  \n",
       "CdxL1ghjiOgZTF8mPLi/JdaUW74ARmq                     [classic, spanish, sangria]  \n",
       "zDZUSIRODtz86LgwPyFH3AoMoPO8p.2             [easy, weeknight, beef, stroganoff]  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datacleaning.clean_recipedata(\"recipes_raw_nosource_ar.json\", n=5000)\n",
    "print(np.shape(data))\n",
    "\n",
    "data\n",
    "# data.to_csv(\"data_small.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"ingredient_words\"] = data.clean_ingredients.apply(word_tokenize)\n",
    "data[\"instruction_words\"] = data.clean_instructions_masked.apply(word_tokenize)\n",
    "\n",
    "data.to_csv(\"data_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingredient_units = {'inch', 'ml', 'milliliter','milliliters','liters','teaspoons', 'l','liter','teaspoon','t','tsp','tablespoon','tablespoons','tbl','tbs','tbsp','ounce','oz','fl','cup','cups','c','pint','pints','pt','p','quart','quarts','qt','gal','gals','gallon','gallons','g','mg','milligram','milligrams','gram','grams','pound','pounds','lb','lbs','c','f'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words(\"english\"))\n",
    "# stop_words = stop_words.union(ingredient_units)\n",
    "\n",
    "# def filter_stop_words(words):\n",
    "#     output = list()\n",
    "#     for word in words:\n",
    "#         if word.casefold() not in stop_words:\n",
    "#             output.append(word)\n",
    "#     return(output)\n",
    "\n",
    "# data[\"instruction_words\"] = data[\"instruction_words\"].apply(filter_stop_words)\n",
    "# data[\"ingredient_words\"] = data[\"ingredient_words\"].apply(filter_stop_words)\n",
    "data['index'] = data.index\n",
    "data.to_csv(\"data_small.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"ingredient_words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_instruction_words = list(itertools.chain.from_iterable(data[\"instruction_words\"]))\n",
    "all_ingredient_words = list(itertools.chain.from_iterable(data[\"ingredient_words\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FreqDist(all_ingredient_words).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions\n",
    "common_instruction_words = []\n",
    "\n",
    "for item in FreqDist(all_instruction_words).items():\n",
    "    if (item[1]) > (len(data)*.01): # remove words that appear less than once per hundred recipes\n",
    "        common_instruction_words.append(item)\n",
    "\n",
    "\n",
    "common_instruction_words = sorted(common_instruction_words, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "common_instruction_words_dict = {}\n",
    "for i in range(len(common_instruction_words)):\n",
    "    common_instruction_words_dict[common_instruction_words[i][0]] = i\n",
    "\n",
    "\n",
    "\n",
    "# Ingredients\n",
    "common_ingredient_words = []\n",
    "for item in FreqDist(all_ingredient_words).items():\n",
    "    if (item[1]) > (len(data)*.01): # remove words that appear less than once per hundred recipes\n",
    "        common_ingredient_words.append(item)\n",
    "\n",
    "common_ingredient_words = sorted(common_ingredient_words, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "common_ingredient_words_dict = {}\n",
    "for i in range(len(common_ingredient_words)):\n",
    "    common_ingredient_words_dict[common_ingredient_words[i][0]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)*.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "ingred = ((pd.DataFrame({a:[b] for a, b in common_ingredient_words})).T.reset_index())\n",
    "ingred = ingred[ingred[0] > 1500]\n",
    "\n",
    "inst = ((pd.DataFrame({a:[b] for a, b in common_instruction_words})).T.reset_index())\n",
    "inst = inst[inst[0] > 2500]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6, 3))\n",
    "\n",
    "a = sns.barplot(y=ingred[0], x=ingred['index'], ax = axes[0])\n",
    "axes[0].tick_params(axis='x', rotation=90)\n",
    "a.set_xlabel(\"\")\n",
    "a.set_ylabel(\"Count\")\n",
    "a.set_title(\"Ingredients\")\n",
    "\n",
    "b = sns.barplot(y=inst[0], x=inst['index'], ax = axes[1])\n",
    "axes[1].tick_params(axis='x', rotation=90)\n",
    "b.set_xlabel(\"\")\n",
    "b.set_ylabel(\"\")\n",
    "b.set_title(\"Instructions\")\n",
    "\n",
    "fig.suptitle(\"Word Frequencies\")\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('figs/original_wordcounts.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_instruction_words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_vectorizer = CountVectorizer(vocabulary=common_instruction_words_dict)\n",
    "\n",
    "ingredient_vectorizer = CountVectorizer(vocabulary=common_ingredient_words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = instruction_vectorizer.fit_transform(data[\"instructions\"])\n",
    "A_ingredients = ingredient_vectorizer.fit_transform(data[\"ingredients\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B = cosine_similarity(A, A[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.histogram(B, bins=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2 = A[0:100,:]\n",
    "# print(np.shape(A2)[0])\n",
    "# G2 = nx.Graph()\n",
    "# for i, attr in data[0:100].iterrows():\n",
    "#     G2.add_node(i, title = attr[0], ingredients = attr[1], instructions = attr[2])\n",
    "\n",
    "# for i in range((np.shape(A2))[0]):\n",
    "#     # if i%1000 == 0: \n",
    "#     #     print(i/(np.shape(A2))[0])\n",
    "#     current_node = data.index[i]\n",
    "#     current_node_similarity = cosine_similarity(A2, A2[i,:])\n",
    "#     for j in range((np.shape(A2))[0]):\n",
    "#         target_node = data.index[j]\n",
    "#         similarity = current_node_similarity[j]\n",
    "#         if (similarity > 0.5 and current_node != target_node): #arbitrary cutoff\n",
    "#             G2.add_edge(current_node, target_node, weight = float(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2 = A_ingredients[0:100,:]\n",
    "# G2 = nx.Graph()\n",
    "# for i, attr in data[0:100].iterrows():\n",
    "#     G2.add_node(i, title = attr[0])\n",
    "\n",
    "# for i in range((np.shape(A2))[0]):\n",
    "#     if i%1000 == 0: \n",
    "#         print(i/(np.shape(A2))[0])\n",
    "#     current_node = data.index[i]\n",
    "#     current_node_similarity = cosine_similarity(A2, A2[i,:])\n",
    "#     edges_to_add = np.argwhere(current_node_similarity > .5)[:,0] #arbitrary cutoff\n",
    "#     for j in edges_to_add:\n",
    "#         target_node = data.index[j]\n",
    "#         similarity = current_node_similarity[j]\n",
    "#         if (current_node != target_node): \n",
    "#             G2.add_edge(current_node, target_node, weight = float(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_node_similarity = cosine_similarity(A, A[1,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thing = np.vstack((np.ravel(current_node_similarity),np.array(range(39522))))\n",
    "\n",
    "# np.shape(thing[:,] > .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for i, attr in data.iterrows():\n",
    "    G.add_node(i, title = attr[0])\n",
    "\n",
    "for i in range((np.shape(A))[0]):\n",
    "    if i%1000 == 0: \n",
    "        print(i/(np.shape(A))[0])\n",
    "    current_node = data.index[i]\n",
    "    current_node_similarity = cosine_similarity(A, A[i,:])\n",
    "    edges_to_add = np.argwhere(current_node_similarity > .5)[:,0] #arbitrary cutoff\n",
    "    for j in edges_to_add:\n",
    "        target_node = data.index[j]\n",
    "        similarity = current_node_similarity[j]\n",
    "        if (current_node != target_node): \n",
    "            G.add_edge(current_node, target_node, weight = float(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, \"recipe_instruction_small.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ingr = nx.Graph()\n",
    "for i, attr in data.iterrows():\n",
    "    G_ingr.add_node(i, title = attr[0])\n",
    "\n",
    "for i in range((np.shape(A_ingredients))[0]):\n",
    "    if i%1000 == 0: \n",
    "        print(i/(np.shape(A_ingredients))[0])\n",
    "    current_node = data.index[i]\n",
    "    current_node_similarity = cosine_similarity(A_ingredients, A_ingredients[i,:])\n",
    "    edges_to_add = np.argwhere(current_node_similarity > .5)[:,0] #arbitrary cutoff\n",
    "    for j in edges_to_add:\n",
    "        target_node = data.index[j]\n",
    "        similarity = current_node_similarity[j]\n",
    "        if (current_node != target_node): \n",
    "            G_ingr.add_edge(current_node, target_node, weight = float(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G_ingr, \"recipe_ingredient_small.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions\n",
    "common_instruction_words = []\n",
    "\n",
    "for item in FreqDist(all_instruction_words).items():\n",
    "    # if (item[1]) > (len(data)*.01): # remove words that appear less than once per hundred recipes\n",
    "    common_instruction_words.append(item)\n",
    "\n",
    "\n",
    "common_instruction_words = sorted(common_instruction_words, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "common_instruction_words_dict = {}\n",
    "for i in range(len(common_instruction_words)):\n",
    "    common_instruction_words_dict[common_instruction_words[i][0]] = i\n",
    "\n",
    "\n",
    "\n",
    "# Ingredients\n",
    "common_ingredient_words = []\n",
    "for item in FreqDist(all_ingredient_words).items():\n",
    "    # if (item[1]) > (len(data)*.01): # remove words that appear less than once per hundred recipes\n",
    "    common_ingredient_words.append(item)\n",
    "\n",
    "common_ingredient_words = sorted(common_ingredient_words, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "common_ingredient_words_dict = {}\n",
    "for i in range(len(common_ingredient_words)):\n",
    "    common_ingredient_words_dict[common_ingredient_words[i][0]] = i\n",
    "\n",
    "\n",
    "instruction_vectorizer = CountVectorizer(vocabulary=common_instruction_words_dict)\n",
    "\n",
    "ingredient_vectorizer = CountVectorizer(vocabulary=common_ingredient_words_dict)\n",
    "\n",
    "A = instruction_vectorizer.fit_transform(data[\"instructions\"])\n",
    "A_ingredients = ingredient_vectorizer.fit_transform(data[\"ingredients\"])\n",
    "\n",
    "\n",
    "G2 = nx.Graph()\n",
    "for i, attr in data.iterrows():\n",
    "    G2.add_node(i, title = attr[0])\n",
    "\n",
    "for i in range((np.shape(A))[0]):\n",
    "    if i%1000 == 0: \n",
    "        print(i/(np.shape(A))[0])\n",
    "    current_node = data.index[i]\n",
    "    current_node_similarity = cosine_similarity(A, A[i,:])\n",
    "    edges_to_add = np.argwhere(current_node_similarity > .5)[:,0] #arbitrary cutoff\n",
    "    for j in edges_to_add:\n",
    "        target_node = data.index[j]\n",
    "        similarity = current_node_similarity[j]\n",
    "        if (current_node != target_node): \n",
    "            G2.add_edge(current_node, target_node, weight = float(similarity))\n",
    "\n",
    "\n",
    "\n",
    "G2_ingr = nx.Graph()\n",
    "for i, attr in data.iterrows():\n",
    "    G2_ingr.add_node(i, title = attr[0])\n",
    "\n",
    "for i in range((np.shape(A_ingredients))[0]):\n",
    "    if i%1000 == 0: \n",
    "        print(i/(np.shape(A_ingredients))[0])\n",
    "    current_node = data.index[i]\n",
    "    current_node_similarity = cosine_similarity(A_ingredients, A_ingredients[i,:])\n",
    "    edges_to_add = np.argwhere(current_node_similarity > .5)[:,0] #arbitrary cutoff\n",
    "    for j in edges_to_add:\n",
    "        target_node = data.index[j]\n",
    "        similarity = current_node_similarity[j]\n",
    "        if (current_node != target_node): \n",
    "            G2_ingr.add_edge(current_node, target_node, weight = float(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G2, \"recipe_instruction_nofilter.gexf\")\n",
    "nx.write_gexf(G2_ingr, \"recipe_ingredient_nofilter.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.linalg.norm(nx.adjacency_matrix(G_ingr) - nx.adjacency_matrix(G2_ingr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.linalg.norm(nx.adjacency_matrix(G) - nx.adjacency_matrix(G2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.linalg.norm(nx.adjacency_matrix(G) - nx.adjacency_matrix(G_ingr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.linalg.norm(nx.adjacency_matrix(G2_ingr) - nx.adjacency_matrix(G2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = list(data[\"clean_instructions_masked\"])\n",
    "ingredients = list(data[\"clean_ingredients\"])\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf2 = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tfidf.fit_transform(instructions)\n",
    "A_ingredients = tfidf2.fit_transform(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_array = np.array(tfidf.get_feature_names_out())\n",
    "tfidf_sorting = np.argsort(tfidf.idf_)[::-1]\n",
    "\n",
    "\n",
    "\n",
    "instructions_idf = pd.DataFrame({\"word\": tfidf.get_feature_names_out(), \"weight\": tfidf.idf_})\n",
    "ingredients_idf = pd.DataFrame({\"word\": tfidf2.get_feature_names_out(), \"weight\": tfidf2.idf_})\n",
    "\n",
    "instructions_idf.to_csv(\"instructions_idf.csv\")\n",
    "ingredients_idf.to_csv(\"ingredients_idf.csv\")\n",
    "\n",
    "\n",
    "# n = 100\n",
    "# top_n = feature_array[tfidf_sorting][:n]\n",
    "# top_n\n",
    "ingredients_idf.sort_values(by=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_array = np.array(tfidf.get_feature_names_out())\n",
    "tfidf_sorting = np.argsort(tfidf.idf_)[::-1]\n",
    "\n",
    "n = 100\n",
    "top_n = feature_array[tfidf_sorting][:n]\n",
    "top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G3 = nx.Graph()\n",
    "for i, attr in data.iterrows():\n",
    "    G3.add_node(i, title = attr[0])\n",
    "\n",
    "for i in range((np.shape(A))[0]):\n",
    "    if i%1000 == 0: \n",
    "        print(i/(np.shape(A))[0])\n",
    "    current_node = data.index[i]\n",
    "    current_node_similarity = cosine_similarity(A, A[i,:])\n",
    "    edges_to_add = np.argwhere(current_node_similarity > .5)[:,0] #arbitrary cutoff\n",
    "    for j in edges_to_add:\n",
    "        target_node = data.index[j]\n",
    "        similarity = current_node_similarity[j]\n",
    "        if (current_node != target_node): \n",
    "            G3.add_edge(current_node, target_node, weight = float(similarity))\n",
    "\n",
    "\n",
    "\n",
    "G3_ingr = nx.Graph()\n",
    "for i, attr in data.iterrows():\n",
    "    G3_ingr.add_node(i, title = attr[0])\n",
    "\n",
    "for i in range((np.shape(A_ingredients))[0]):\n",
    "    if i%1000 == 0: \n",
    "        print(i/(np.shape(A_ingredients))[0])\n",
    "    current_node = data.index[i]\n",
    "    current_node_similarity = cosine_similarity(A_ingredients, A_ingredients[i,:])\n",
    "    edges_to_add = np.argwhere(current_node_similarity > .5)[:,0] #arbitrary cutoff\n",
    "    for j in edges_to_add:\n",
    "        target_node = data.index[j]\n",
    "        similarity = current_node_similarity[j]\n",
    "        if (current_node != target_node): \n",
    "            G3_ingr.add_edge(current_node, target_node, weight = float(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G3, \"recipe_instruction_tfidf.gexf\")\n",
    "nx.write_gexf(G3_ingr, \"recipe_ingredient_tfidf.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G4 = nx.Graph()\n",
    "for i, attr in data.iterrows():\n",
    "    G4.add_node(i, title = attr[0])\n",
    "\n",
    "for i in range((np.shape(A))[0]):\n",
    "    if i%1000 == 0: \n",
    "        print(i/(np.shape(A))[0])\n",
    "    current_node = data.index[i]\n",
    "    current_node_similarity = cosine_similarity(A, A[i,:])\n",
    "    edges_to_add = np.argsort(np.squeeze(current_node_similarity))[::-1]\n",
    "    edges_to_add = np.squeeze(edges_to_add[:3])\n",
    "    # b = np.argwhere(current_node_similarity > .5)[:,0] #arbitrary cutoff\n",
    "    for j in edges_to_add:\n",
    "        target_node = data.index[j]\n",
    "        similarity = current_node_similarity[j]\n",
    "        if (current_node != target_node): \n",
    "            G4.add_edge(current_node, target_node, weight = float(similarity))\n",
    "\n",
    "\n",
    "\n",
    "G4_ingr = nx.Graph()\n",
    "for i, attr in data.iterrows():\n",
    "    G4_ingr.add_node(i, title = attr[0])\n",
    "\n",
    "for i in range((np.shape(A_ingredients))[0]):\n",
    "    if i%1000 == 0: \n",
    "        print(i/(np.shape(A_ingredients))[0])\n",
    "    current_node = data.index[i]\n",
    "    current_node_similarity = cosine_similarity(A_ingredients, A_ingredients[i,:])\n",
    "    # edges_to_add = np.argwhere(current_node_similarity > .5)[:,0] #arbitrary cutoff\n",
    "    edges_to_add = np.argsort(np.squeeze(current_node_similarity))[::-1]\n",
    "    edges_to_add = np.squeeze(edges_to_add[:3])\n",
    "    for j in edges_to_add:\n",
    "        target_node = data.index[j]\n",
    "        similarity = current_node_similarity[j]\n",
    "        if (current_node != target_node): \n",
    "            G4_ingr.add_edge(current_node, target_node, weight = float(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_node_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G4, \"recipe_instruction_ranked_tfidf.gexf\")\n",
    "nx.write_gexf(G4_ingr, \"recipe_ingredient_ranked_tfidf.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\"k9Wo2oKtwveioGZll5XyvYnviGvJr72\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\"iPiuCa80W95Q1hwpAvNcQoAK3GOonMq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_vectorizer = CountVectorizer(max_df= .5, min_df= 0.0, binary=True)\n",
    "\n",
    "ingredient_vectorizer = CountVectorizer(max_df= .5, min_df= 0.0, binary=True)\n",
    "\n",
    "A = instruction_vectorizer.fit_transform(data[\"instructions\"])\n",
    "A_ingredients = ingredient_vectorizer.fit_transform(data[\"ingredients\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G5 = nx.Graph()\n",
    "for i, attr in data.iterrows():\n",
    "    G5.add_node(i, title = attr[0])\n",
    "\n",
    "for i in range((np.shape(A))[0]):\n",
    "    if i%1000 == 0: \n",
    "        print(i/(np.shape(A))[0])\n",
    "    current_node = data.index[i]\n",
    "    current_node_similarity = cosine_similarity(A, A[i,:])\n",
    "    edges_to_add = np.argwhere(current_node_similarity > .5)[:,0] #arbitrary cutoff\n",
    "    for j in edges_to_add:\n",
    "        target_node = data.index[j]\n",
    "        similarity = current_node_similarity[j]\n",
    "        if (current_node != target_node): \n",
    "            G5.add_edge(current_node, target_node, weight = float(similarity))\n",
    "\n",
    "\n",
    "G5_ingr = nx.Graph()\n",
    "for i, attr in data.iterrows():\n",
    "    G5_ingr.add_node(i, title = attr[0])\n",
    "\n",
    "for i in range((np.shape(A_ingredients))[0]):\n",
    "    if i%1000 == 0: \n",
    "        print(i/(np.shape(A_ingredients))[0])\n",
    "    current_node = data.index[i]\n",
    "    current_node_similarity = cosine_similarity(A_ingredients, A_ingredients[i,:])\n",
    "    edges_to_add = np.argwhere(current_node_similarity > .5)[:,0] #arbitrary cutoff\n",
    "    for j in edges_to_add:\n",
    "        target_node = data.index[j]\n",
    "        similarity = current_node_similarity[j]\n",
    "        if (current_node != target_node): \n",
    "            G5_ingr.add_edge(current_node, target_node, weight = float(similarity)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G5, \"recipe_instruction_binary.gexf\")\n",
    "nx.write_gexf(G5_ingr, \"recipe_ingredient_binary.gexf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
